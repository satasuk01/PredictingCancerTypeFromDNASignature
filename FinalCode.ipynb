{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalCode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol_Ra9pYxd6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filepaths\n",
        "top50genesPaper_SPM = '/content/drive/My Drive/Proj Senior/top50genesPaper_SPM.txt'\n",
        "top50genesPaper_CNA = '/content/drive/My Drive/Proj Senior/top50genesPaper_CNA.txt'\n",
        "\n",
        "# Dataset\n",
        "spm_path = \"/content/drive/My Drive/Proj Senior/SomaticPointMutationMatrix.csv\"\n",
        "cna_path = \"/content/drive/My Drive/Proj Senior/CopyNumberAlterationMatrix.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJBO7rPo2r3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load libraries\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install catboost\n",
        "import pandas as pd\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgbm\n",
        "from catboost import CatBoostClassifier\n",
        "from catboost import core"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ZGQX379vj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Preaparation\n",
        "topPaperSPM = []\n",
        "topPaperCNA = []\n",
        "for line in open(top50genesPaper_SPM):\n",
        "  topPaperSPM.append(line.strip())\n",
        "for line in open(top50genesPaper_CNA):\n",
        "  topPaperCNA.append(line.strip())\n",
        "\n",
        "top50paper = topPaperSPM+topPaperCNA\n",
        "\n",
        "def count_gene(features):\n",
        "  CNA = set()\n",
        "  SPM = set()\n",
        "  READY = set()\n",
        "  for gene in features:\n",
        "    if '.n' in gene:\n",
        "      CNA.add(gene.replace('.n',''))\n",
        "      READY.add(gene)\n",
        "      READY.add(gene.replace('.n','.p'))\n",
        "    elif '.p' in gene:\n",
        "      CNA.add(gene.replace('.p',''))\n",
        "      READY.add(gene)\n",
        "      READY.add(gene.replace('.p','.n'))\n",
        "    else:\n",
        "      READY.add(gene)\n",
        "      SPM.add(gene)\n",
        "  print('spm: {}'.format(len(SPM)))\n",
        "  print('cna: {}'.format(len(CNA)))\n",
        "  print('gene: {}'.format(len(CNA.union(SPM))))\n",
        "  return READY\n",
        "\n",
        "spm = pd.read_csv(spm_path)\n",
        "cna = pd.read_csv(cna_path)\n",
        "merged_df = pd.merge(spm,cna,on='Unnamed: 0')\n",
        "merged_df = merged_df.drop(columns=['classLabels_y'])\n",
        "merged_df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "features_name_all =  list(merged_df.drop(['classLabels_x'], axis=1).columns) # get all features name\n",
        "\n",
        "selected_paper_df = merged_df[top50paper+['classLabels_x']]\n",
        "\n",
        "catboostAllRemove = set(top50paper) - set(['GNA11','NPM1', 'RGPD3', 'GNAQ','RBM4'])\n",
        "catboostAllRemove = merged_df[list(catboostAllRemove)+['classLabels_x']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCnkzmxCjiFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kcv1 = StratifiedKFold(n_splits=5, random_state=108, shuffle=True)\n",
        "\n",
        "# ===============================================================\n",
        "# SELECT MODEL\n",
        "# model = LinearSVC()\n",
        "# model = XGBClassifier(importance_type = 'cover', n_jobs = 4, verbose_eval = 4) # “gain”, “weight”, “cover”, “total_gain” or “total_cover”.\n",
        "model = RandomForestClassifier()\n",
        "# model = AdaBoostClassifier(SVC(probability=True, kernel='linear'), n_estimators=50, random_state=0) # tryna add verbose=1\n",
        "# model = lgbm.LGBMClassifier()\n",
        "# model = CatBoostClassifier()\n",
        "\n",
        "# SELECT Dataset\n",
        "# features = merged_df.copy() # all genes\n",
        "features = selected_paper_df # 50 genes\n",
        "# features = catboostAllRemove # Remove 5 genes\n",
        "\n",
        "classLabels = range(29)[1:]\n",
        "\n",
        "feature_names = list(features.drop(['classLabels_x'], axis=1).columns)\n",
        "\n",
        "X = features.drop(['classLabels_x'], axis=1)\n",
        "y = features['classLabels_x']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTeCDcw13LcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K-FOLD CROSS VALIDATION =======================================\n",
        "reports = []\n",
        "\n",
        "scores = []\n",
        "evas = []\n",
        "reps = []\n",
        "\n",
        "imps = []\n",
        "\n",
        "START_TIME = time.time()\n",
        "\n",
        "\n",
        "for train_idx, test_idx in kcv1.split(X,y):\n",
        "    print('Start split')\n",
        "\n",
        "    coef_ = []\n",
        "    X_train, X_test, y_train, y_test = X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    # features.append(model.feature_importances_)\n",
        "    confs = confusion_matrix(y_test, y_pred)\n",
        "    # coef_ = model.coef_ # for svm only\n",
        "    reports.append({\n",
        "      'scores': accuracy_score(y_test, y_pred, normalize=True, sample_weight=None),\n",
        "      # 'imp': np.copy(model.feature_importances_),\n",
        "      # 'shap': model.get_feature_importance(data=X_train,type=core.EFstrType.ShapValues),\n",
        "      'evas': precision_recall_fscore_support(y_test, y_pred, average=None),\n",
        "      'reps': classification_report(y_test, y_pred),\n",
        "      'coef_': coef_,\n",
        "      'confs': confs,\n",
        "      'precision_micro':  precision_score(y_test, y_pred, average='micro'),\n",
        "      'recall_micro': recall_score(y_test, y_pred, average='micro'),\n",
        "      'f1score_micro': f1_score(y_test, y_pred, average='micro'),\n",
        "    })\n",
        "    print('checkpoint: {} min'.format((time.time()-START_TIME)/60))\n",
        "\n",
        "print('take {} min'.format((time.time()-START_TIME)/60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyG0L9Yr-y07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate report\n",
        "acc_array = []\n",
        "\n",
        "precision_array = []\n",
        "recall_array = []\n",
        "f1score_array = []\n",
        "support_array = []\n",
        "\n",
        "micro_precision_array = []\n",
        "micro_recall_array = []\n",
        "micro_f1score_array = []\n",
        "\n",
        "for rep in reports:\n",
        "  # print(rep['evas'][0][27])\n",
        "  precision_array.append(rep['evas'][0])\n",
        "  recall_array.append(rep['evas'][1])\n",
        "  f1score_array.append(rep['evas'][2])\n",
        "  support_array.append(rep['evas'][3])\n",
        "  micro_precision_array.append(rep['precision_micro'])\n",
        "  micro_recall_array.append(rep['recall_micro'])\n",
        "  micro_f1score_array.append(rep['f1score_micro'])\n",
        "  acc_array.append(rep['scores'])\n",
        "\n",
        "avg_precision = np.mean(precision_array,axis = 0) \n",
        "avg_recall = np.mean(recall_array,axis = 0)\n",
        "avg_f1score = np.mean(f1score_array, axis = 0)\n",
        "avg_support = np.mean(support_array, axis=0)\n",
        "std_precision = np.std(precision_array,axis=0)\n",
        "std_recall = np.std(recall_array,axis=0)\n",
        "std_f1score = np.std(f1score_array,axis=0)\n",
        "std_support = np.std(support_array,axis=0)\n",
        "item = {\n",
        "    'label': classLabels,\n",
        "    'precision': avg_precision,    \n",
        "    'recall': avg_recall,\n",
        "    'f1score': avg_f1score,\n",
        "    'support': avg_support,\n",
        "    'std_precision': std_precision,\n",
        "    'std_recall': std_recall,\n",
        "    'std_f1score': std_f1score,\n",
        "    'std_support': std_support,    \n",
        "}\n",
        "\n",
        "# pd.DataFrame(item).to_excel('/content/drive/My Drive/Proj Senior/Reports/AfterProgress/Rep/CAT50.xlsx')\n",
        "macro_avg_precision = np.mean(avg_precision)\n",
        "macro_avg_recall = np.mean(avg_recall)\n",
        "macro_avg_f1 = 2 * (macro_avg_precision * macro_avg_recall) / (macro_avg_precision + macro_avg_recall)\n",
        "micro_precision = np.mean(micro_precision_array)\n",
        "micro_recall = np.mean(micro_recall_array)\n",
        "micro_f1score = np.mean(micro_f1score_array)\n",
        "acc = np.mean(acc_array)\n",
        "print('''macro\\tprecision: {}\\trecall: {}\\tf1score: {}\n",
        "micro\\tprecision: {}\\trecall: {}\\tf1score: {}\n",
        "acc: {}'''.format(macro_avg_precision,macro_avg_recall,macro_avg_f1,micro_precision,micro_recall,micro_f1score,acc))\n",
        "print('std acc: {}'.format(np.std([e['scores'] for e in reports])))\n",
        "print([e['scores'] for e in reports])\n",
        "print('====data info====')\n",
        "count_gene(feature_names)\n",
        "print('====END====')\n",
        "print(acc)\n",
        "print(macro_avg_precision)\n",
        "print(macro_avg_recall)\n",
        "print(macro_avg_f1)\n",
        "print(micro_precision)\n",
        "print(micro_recall)\n",
        "print(micro_f1score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTJzDovY2B7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}